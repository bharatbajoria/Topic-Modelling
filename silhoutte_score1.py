# -*- coding: utf-8 -*-
"""Silhoutte Score.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tzWB38-o8QvClyKZZ-_C_XXVAh7pAZBY
"""

def tokens(All_docs,RegexpTokenizer,stopwords,sent_tokenize):
  tokenizer = RegexpTokenizer(r'\w+')
  en_stop = set(stopwords.words('english'))
  en_stop.add('the')#The is not in stopwords
  tokens=[]
  for j in All_docs:
    x=[]
    
    for i in j:
      y=sent_tokenize(i)
      for k in y:
        token=tokenizer.tokenize(k)
        #print(token)
        token=[i for i in token if(not(str(i).isdigit() or not(str(i).isalpha())) and len(str(i)) > 2 )]
        token=[i.lower() for i in token if( i not in en_stop)]
        if len(token)>0:
          x.append(token)
        
      tokens.extend(x)

  return tokens

def clusters(TfidfVectorizer,tokens,KMeans,silhouette_score,max_cluster):
  tk=[]  
  for i in tokens:
    tk.extend(i)
  
  tokens=tk[:]
  n=0
  ss=0
  vectorizer = TfidfVectorizer()
  Y = vectorizer.fit_transform(tokens)
  
  for n_cluster in range(2, max_cluster):
      kmeans = KMeans(n_clusters=n_cluster).fit(Y)
      label = kmeans.labels_
      sil_coeff = silhouette_score(Y, label, metric='euclidean')  
      
      if sil_coeff>ss:
        ss=sil_coeff
        n=n_cluster
  return n